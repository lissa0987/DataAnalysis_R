---
title: "HW 2: From correlation to linear mixed-effect models. Assignment sheet"
---

```{r setup, include=FALSE}
library(tidyverse)
library(lme4)
library(vcd)
```

## 1. Vowel reduction in Russian
Pavel Duryagin ran an experiment on perception of vowel reduction in Russian language. The dataset `shva` includes the following variables:  
_time1_ - reaction time 1  
_duration_ - duration of the vowel in the stimuly (in milliseconds, ms)  
_time2_ - reaction time 2  
_f1_, _f2_, _f3_ - the 1st, 2nd and 3rd formant of the vowel measured in Hz (for a short introduction into formants, see [here](https://home.cc.umanitoba.ca/~krussll/phonetics/acoustic/formants.html))  
_vowel_ - vowel classified according the 3-fold classification (_A_ - _a_ under stress, _a_ - _a/o_ as in the first syllable before the stressed one, _y_ (stands for shva) - _a/o_ as in the second etc. syllable before the stressed one or after the stressed syllable, cf. _g_[_y_]_g_[_a_]_t_[_A_]_l_[_y_] _gogotala_ `guffawed').  
In this part, we will ask you to analyse correlation between f1, f2, and duration.
The dataset is available [https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/duryagin_ReductionRussian.txt](here).

### 1.0 Read the data from file to the variable `shva`.
```{r 1.0}
shva <- read_tsv("C:/Users/User/Desktop/duryagin_ReductionRussian.txt")
```

### 1.1 Scatterplot `f1` and `f2` using `ggplot()`. 
Design it to look like the [following](https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/img/duryagin1.png).
```{r 1.1}
ggplot(data = shva, aes(y = f1, x = f2, color=vowel)) +
  geom_point() + ggtitle("f1 and f2 of the reduced and stressed vowels") + 
  scale_y_reverse() + scale_x_reverse() +  theme(legend.position="none") + labs(caption = "Data from Duryagin 2018") 
```

### 1.2 Plot the boxplots of `f1` and `f2` for each vowel using `ggplot()`.
Design it to look like [this](https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/img/duryagin2.png) and [this](https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/img/duryagin3.png).
```{r 1.2}
# f1 boxplot
shva %>% ggplot(aes(vowel,f1, fill=vowel) )+ 
geom_boxplot()+coord_flip()+ 
labs(title="f1 distribution in each vowel",y = "f1", x='')+theme(legend.position="none")+labs(caption = "data from Duryagin 2018") 
# f2 boxplot 
shva %>% ggplot(aes(vowel,f2, fill=vowel) )+ 
geom_boxplot()+coord_flip()+ 
labs(title="f2 distribution in each vowel",y = "f1", x='')+theme(legend.position="none")+labs(caption = "data from Duryagin 2018")
```

### 1.3 Which `f1` can be considered outliers in _a_ vowel?
We assume outliers to be those observations that lie outside 1.5 * IQR, where IQR, the 'Inter Quartile Range', is the difference between the 1st and the 3rd quartile (= 25% and 75% percentile).
```{r 1.3}
a_shva <- shva %>%
  filter(shva$vowel=="a")

res <- which(a_shva$f1 < quantile(a_shva$f1)[2] - 1.5 * IQR(shva_a$f1)  | a_shva$f1 > quantile(a_shva$f1)[4] + 1.5 * IQR(a_shva$f1))
a_shva$f1[res]


```

### 1.4 Calculate Pearson's correlation of `f1` and `f2` (all data)
```{r 1.4}
cor(shva[,4:5], method="pearson")
```

### 1.5 Calculate Pearson's correlation of `f1` and `f2` for each vowel
```{r 1.5}
a_shva <- shva %>%
filter(shva$vowel=="a") 
cor(a_shva[,4:5],method='pearson')

y_shva <- shva %>%
filter(shva$vowel=="y") 
cor(a_shva[,4:5],method='pearson')

A_shva <- shva %>%
filter(shva$vowel=="A") 
cor(a_shva[,4:5],method='pearson')
```
### 1.6 Use the linear regression model to predict f2 by f1
```{r}
#f2 by f1
lm_shva <- lm(f2~f1, data=shva)
summary(lm_shva)
coefficients(lm_shva)
```
### 1.6.1 Provide the result regression formula
$$1639.70215 - 0.42875\cdot x$$
$$1639.70215 - 0.42875\cdot x + e, \\  e \sim N(0, 71.51^{2})$$

### 1.6.2 Provide the adjusted R-squared
$$0.3319$$

### 1.6.3 Add the regression line in scatterplot 1.1
```{r}
shva_lm2 <- lm(f1~f2, data=shva)
shva$model <- predict(shva_lm2)
ggplot(data = shva, aes(y = f1, x = f2, color=vowel)) +
  geom_point() + ggtitle("f1 and f2 of the reduced and stressed vowels") + 
  scale_x_reverse() + scale_y_reverse()  + theme(legend.position="none") + labs(caption = "Data from Duryagin 2018")+
  geom_line(aes(f2, model), color = "black")
```
## 1.7 Use the mixed-efects model to predict f2 by f1 using vowel intercept as a random effect
```{r}
shva_rlm <- lmer(f2~f1 + (1|vowel), data=shva)
summary(shva_rlm)
fixef(shva_rlm)
```
## 1.7.1 Provide the fixed effects formula
$$ 1356 + 0.0689\cdot x$$
## 1.7.2 Provide the variance for intercept argument for vowel random effects
$$6374$$
## 1.7.3 Add the regression line in scatterplot 1.1
```{r}
shva_rlm2 <- lmer(f1~f2 + (1|vowel), data=shva)
shva$random <- predict(shva_rlm2)
ggplot(data = shva, aes(y = f1, x = f2, color=vowel)) +
  geom_point() + ggtitle("f1 and f2 of the reduced and stressed vowels") + 
  scale_y_reverse() + scale_x_reverse() +   theme(legend.position="none") + labs(caption = "Data from Duryagin 2018") +
geom_line(aes(f2, random, color = vowel))
```


## 2. English Lexicon Project data
880 nouns, adjectives and verbs from the English Lexicon Project data (Balota et al. 2007).

* `Format` -- A data frame with 880 observations on the following 5 variables.
* `Word` -- a factor with lexical stimuli.
* `Length` -- a numeric vector with word lengths.
* `SUBTLWF` -- a numeric vector with frequencies in film subtitles.
* `POS` -- a factor with levels JJ (adjective) NN (noun) VB (verb)
* `Mean_RT` -- a numeric vector with mean reaction times in a lexical decision task
Source (http://elexicon.wustl.edu/WordStart.asp)

Data from Natalya Levshina's `RLing` package available (here)[https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/ELP.csv]

### 2.0 Read the data from file to the variable `elp`.
```{r 2.0}
elp <- read.csv('https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/ELP.csv')
```

### 2.1 Which two variables have the highest Pearson's correlaton value?
```{r 2.1}
a1 <- cor(elp[,2:3],method='pearson')
a2 <- cor(elp[,c(2,5)],method='pearson')
a3 <- cor(elp[,c(3,5)],method='pearson')
a2
print("Length and Mean_RT has the highest Pearson's correlation value")
```

### 2.2 Group your data by parts of speech and make a scatterplot of SUBTLWF and Mean_RT.
```{r 2.2}
elp %>%
  ggplot(aes(SUBTLWF, Mean_RT, color = Length))+
  geom_point()+
  facet_wrap(~POS)+
  scale_color_continuous(low = "lightblue", high = "red")+
  labs(caption = "data from (Balota et al.2007)")+ theme_bw() +
  scale_x_log10()
```

We've used `scale_color_continuous(low = "lightblue", high = "red")` as a parameter of `ggplot()`.

### 2.3 Use the linear regression model to predict `Mean_RT` by `log(SUBTLWF)` and `POS`.
#### 2.3.1 Provide the result regression formula
```{r 2.3.1}
elp_lm <- lm(Mean_RT~log(SUBTLWF)+POS, data=elp)
summary(elp_lm)
coefficients(elp_lm)
```
$$ 786.176 -37.573x_1-12.530x_2-42.804x_3$$
$$786.176 -37.573x_1-12.530x_2-42.804x_3 + e, \\  e \sim N(0, 102.7^{2})$$
#### 2.3.2 Provide the adjusted R$^2$
```{r 2.3.2}
print(0.3385)

```
$$0.3385$$
#### 2.3.3 Add the regression line in the scatterplot.
```{r 2.3.3}
elp_lm2 <- lm(Mean_RT~log(SUBTLWF), data=elp)
elp_model <- predict(elp_lm2)

elp %>% 
  ggplot(aes(log(SUBTLWF), Mean_RT, color = Length))+ 
  geom_point() + scale_color_continuous(low = "lightblue", high = "red") + labs(caption = "data from (Balota et al.2007)")+ theme_bw() + 
  geom_line(aes(log(SUBTLWF), elp_model), color = "black")
```

### 2.4 Use the mixed-efects model to predict `Mean_RT` by `log(SUBTLWF)` using POS intercept as a random effect

#### 2.4.1 Provide the fixed effects formula
```{r 2.4.1}
elp_rlm <- lmer(Mean_RT~log(SUBTLWF) + (1|POS), data=elp)
summary(elp_rlm)
fixef(elp_rlm)
```
$$767.70941-37.666x$$
#### 2.4.2 Provide the variance for intercept argument for `POS` random effects
```{r 2.4.2}
print(414.4)
```
$$414.4$$
#### 2.4.3 Add the regression line to the scatterplot
```{r 2.4.3}
elp_rlm2 <- lmer(Mean_RT~log(SUBTLWF) + (1|POS), data=elp)
elp$random <- predict(elp_rlm2)
elp %>% 
ggplot(aes(log(SUBTLWF), Mean_RT, color = POS))+ 
geom_point()+ 
facet_wrap(~POS)+ 
labs(caption = "data from (Balota et al.2007)") +
theme(legend.position="none") + geom_line(aes(log(SUBTLWF), random), color = "black")

```

## 3. Dutch causative constructions

This is a data set with examples of two Dutch periphrastic causatives extracted from newspaper corpora.

The data frame includes 100 observations on the following 7 variables:

* Cx -- a factor with levels doen_V and laten_V
* CrSem -- a factor that contains the semantic class of the Causer with levels Anim (animate) and Inanim (inanimate).
* CeSem -- a factor that describes the semantic class of the Causee with levels Anim (animate) and Inanim (inanimate).
* CdEv -- a factor that describes the semantic domain of the caused event expressed by the Effected Predicate. The levels are Ment (mental), Phys (physical) and Soc (social).
* Neg -- a factor with levels No (absence of negation) and Yes (presence of negation).
* Coref -- a factor with levels No (no coreferentiality) and Yes (coreferentiality).
* Poss -- a factor with levels No (no overt expression of possession) Yes (overt expression of possession)

Data from Natalya Levshina's `RLing` package available (here)[https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/dutch_causatives.csv]

### 3.0 Read the data from file to the variable `d_caus`.
```{r 3.0}
d_caus <- read.csv("https://raw.githubusercontent.com/agricolamz/2018-MAG_R_course/master/data/dutch_causatives.csv")
```

### 3.1 We are going to test whether the association between `Aux` and other categorical variables (`Aux` ~ `CrSem`, `Aux` ~ `CeSem`, etc) is statistically significant. The assiciation with which variable should be analysed using Fisher's Exact Test and not using Pearson's Chi-squared Test? Is this association statistically significant?
```{r 3.1}
#`Aux` ~ `CrSem`
table <- table(d_caus$Aux, d_caus$CrSem)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("Using chi-squared is possible. The assosiation is significant as p-value < 2.2e-16")

#`Aux` ~ `CeSem`
table <- table(d_caus$Aux, d_caus$CeSem)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("Using chi-squared is possible. The assosiation is insignificant as p-value = 0.06778")

#`Aux` ~ `CdEvSem`
table <- table(d_caus$Aux, d_caus$CdEvSem)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("Using chi-squared is possible. The assosiation is significant as p-value = 2.144e-05")

#`Aux` ~ `CeSynt`
table <- table(d_caus$Aux, d_caus$CeSynt)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("It is better to use Fisher's Exact Test bucause od low expectation value (3.74). The assosiation is significant as p-value = 1.88e-15")

#`Aux` ~ `EPTrans`
table <- table(d_caus$Aux, d_caus$EPTrans)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("Using chi-squared is possible. The assosiation is significant as p-value = 0.0001553")

#`Aux` ~ `Country`
table <- table(d_caus$Aux, d_caus$Country)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("Using chi-squared is possible. The assosiation is significant as p-value = 0.0001127")

#`Aux` ~ `Domain`
table <- table(d_caus$Aux, d_caus$Domain)
chisq.test(table)
exp <- chisq.test(table)$expected
exp
print("Using chi-squared is possible. The assosiation is significant as p-value = 2.014e-06")
```

### 3.2. Test the hypothesis that `Aux` and `EPTrans` are not independent with the help of Pearson's Chi-squared Test. 
```{r 3.2}
table <- table(d_caus$Aux, d_caus$EPTrans)
table
chisq.test(table)
print("The hypothesis that Aux and EPTrans are not independent is rejected as p-value is 0.0001553 that is lower than 0.05")

```

### 3.3 Provide expected values for Pearson's Chi-squared Test of `Aux` and `EPTrans` variables.
```{r 3.3}
chisq.test(table)$expected
```

### 3.4. Calculate the odds ratio.
```{r 3.4}
fisher.test(table)
oddsratio(table)
print('odds ration is 2.601174')
```

### 3.5 Calculate effect size for this test using Cramer's V (phi).
```{r 3.5}
library(psych)
print(phi(table))
#(57/(57+28))/(182/(182+233))
```

### 3.6. Report the results of independence test using the following template:
```
We have found a significant association between variables `Aux` and `EPTrans` (p < 0.001).  The odds of effected predicate beeing intransitive were 1.529089 times higher in (group of doen) than in (group of laten). Effect size is small (Cramer's V = 0.1752191).
```

### 3.7 Visualize the distribution using mosaic plot.
Use `mosaic()` function from `vcd` library.
```{r 3.7}
mosaic(~ Aux + EPTrans, data=d_caus, shade=TRUE, legend=TRUE)
```

Below is an example of how to use mosaic() with three variables.
```{r 3.7.1}
# mosaic(~ Aux + CrSem + Country, data=d_caus, shade=TRUE, legend=TRUE)
```

### 3.8 Why is it not recommended to run multiple Chisq tests of independence on different variables within your dataset whithout adjusting for the multiplicity? (i.e. just testing all the pairs of variables one by one)  
```
That may cause an error of the first kind as a true null hypothesis can be rejected. 
```

### 3.9 Provide a short text (300 words) describing the hypothesis on this study and the results of your analysis.

According to the hypothesis of this study the choice between the causative constructions with doen and laten may depend on animacy of a causer or causee, the semantic domain of the caused event, transitivity/intransitivity of an effected predicate, Netherlandic or Belgian variety of Dutch, information about the domain. As a result of chi-squared test we have that Aux and EPTrans are dependent and this dependency is statistically significant. Also, the odds ratio and effect size show the choice between doen and laten depends on transitivity so the analysis shows that the probability of the verb doen is greater if an effected predicate in intransitive whereas the verb laten is higher if a predicate is intransitive.    
